{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LaneNet.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyN/iBSTMHncjkOOmw1fW0ys"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"QeV3ULVuvOwr","colab_type":"text"},"source":["#### * _We used Pytorch for our CNN models_ *"]},{"cell_type":"markdown","metadata":{"id":"vmerq4CX4wXB","colab_type":"text"},"source":["# __Why Detect Lane Markings__\n","For our project, we are interested in working on lane detection for autonomous vehicles using lane markings painted on the roads. The task of lane detection is still vital to the success of autonomous vehicles because it is pertinent that an autonomous vehicle can exactly recognize which lane it is in and where it needs to go. If it is not able to do that, the vehicles might be going in the middle of two lanes which can be dangerous for other vehicles in the vicinity. Also, lane detection is inevitable to perform maneuvers like lane changes and also for predicting other vehiclesâ€™ behavior."]},{"cell_type":"markdown","metadata":{"id":"fKhKOATu5O3h","colab_type":"text"},"source":["# __Build a lane extractor from an image__\n","In this project, we tried to train a Convolutional Neural Network (CNN) to extract lane markings as features from given images of roads with lanes. \n","\n","### __Dataset Description__\n","We plan on using the __CULane Dataset__ (Chinese University Lane Dataset) which contains 88,880 images for the training set, 9,675 images for the validation set and 34,680 images for the test set. Furthermore, the test set is divided into one normal and 8 challenging categories that tests the network on harder images. The dataset is desirable because it contains images from a variety of settings like crowded, night, no line, shadow, curve, etc. Such diversity in the dataset is desirable for training the model.\t\n","\n","### __Modelling Pipeline__\n","  1. Extract the images from the dataset stored on Drive\n","  2. Organize the images into raw images and labelled value\n","  3. Train the Model\n","  4. Get a reasonable validation accuracy\n","  5. Test the Model on unseen images "]},{"cell_type":"code","metadata":{"id":"dl2uVXeSSKs5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"48e8e1cc-db67-4ae0-f92a-175134ff5ff5","executionInfo":{"status":"ok","timestamp":1589789697415,"user_tz":420,"elapsed":4373,"user":{"displayName":"ASHAR ALAM","photoUrl":"","userId":"03610029456235520310"}}},"source":["# this mounts your Google Drive to the Colab VM.\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","from os.path import join\n","import os\n","\n","ROOT = '/content/drive'     # default for the drive\n","CODE = 'My Drive/cs231n/Project/LaneNet'       # path to our code on Drive\n","DATASET = 'My Drive/cs231n/Project/dataset/trainset'\n","\n","CODE_PATH = join(ROOT, CODE)\n","DATASET_PATH = join(ROOT, DATASET)\n","\n","# now that we've mounted your Drive, this ensures that\n","# the Python interpreter of the Colab VM can load\n","# python files from within it.\n","import sys\n","sys.path.append('{}'.format(CODE_PATH))\n","\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"e5MbCxwYosSK","colab_type":"text"},"source":["## Some Imports\n"]},{"cell_type":"code","metadata":{"id":"bpBO4d7C1zsZ","colab_type":"code","colab":{}},"source":["import json\n","import numpy as np\n","import cv2\n","import matplotlib.pyplot as plt\n","%matplotlib inline"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fra934wNp3jN","colab_type":"text"},"source":["### Let's visualize some of the images we have\n","We have a contiguous set of 20 images frame-by-frame for each scene, with the 20th frame labelled in our dataset. <br>\n","Let's visualize these images to understand what each scene information contains:\n"]},{"cell_type":"code","metadata":{"id":"4ZCiD7TQp7bP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":55},"outputId":"25819305-c510-4bd2-a0c9-a4e214ed8841","executionInfo":{"status":"ok","timestamp":1589788579229,"user_tz":420,"elapsed":592,"user":{"displayName":"ASHAR ALAM","photoUrl":"","userId":"03610029456235520310"}}},"source":["# Obtaining a list of paths for each image\n","\"\"\"\n","FIXED_PATH = DATASET_PATH + '/clips/0313-1/60/'\n","items = os.listdir(FIXED_PATH)\n","n_images = len(items)\n","plt_idx = 0\n","fig = plt.figure()\n","n_cols = 20\n","for image in items: \n","  plt_idx += 1\n","  full_path = FIXED_PATH + image\n","  a = fig.add_subplot(n_cols, np.ceil(n_images/float(n_cols)), plt_idx)\n","  img = plt.imread(full_path)\n","  #plt.imshow(img.astype('uint8'))\n","fig.set_size_inches(np.array(fig.get_size_inches()) * n_images)\n","plt.show()\n","\"\"\""],"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"\\nFIXED_PATH = DATASET_PATH + '/clips/0313-1/60/'\\nitems = os.listdir(FIXED_PATH)\\nn_images = len(items)\\nplt_idx = 0\\nfig = plt.figure()\\nn_cols = 20\\nfor image in items: \\n  plt_idx += 1\\n  full_path = FIXED_PATH + image\\n  a = fig.add_subplot(n_cols, np.ceil(n_images/float(n_cols)), plt_idx)\\n  img = plt.imread(full_path)\\n  #plt.imshow(img.astype('uint8'))\\nfig.set_size_inches(np.array(fig.get_size_inches()) * n_images)\\nplt.show()\\n\""]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"markdown","metadata":{"id":"G5lc3KUNpbCp","colab_type":"text"},"source":["# __1. Extract the images from the dataset stored on Drive__ \n","\n","We have already done so in our Operational.ipynb notebook"]},{"cell_type":"markdown","metadata":{"id":"zTqaGO9R0M3W","colab_type":"text"},"source":["# __2. Organize the images into raw images and labelled value__\n","\n","Here, we will generate labelled data for our train, validation and test splits. We will generate labelled data as bindary masks since the original dataset doesn't come preloaded with this information.\n","<br>\n","Moreover, instead of loading data manually, we decided on using Pytorch to create a custom Dataset and DataLoader\n","<br> \n","More details on the DataLoader setup can be found in `LaneNet/Data/Tusimple.py`\n","<br>\n","\n","## Some imports for the modules"]},{"cell_type":"code","metadata":{"id":"bNyuHgkTo0QB","colab_type":"code","colab":{}},"source":["import argparse\n","import json\n","import os\n","import shutil\n","import time\n","\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","from tqdm import tqdm\n","\n","#from config import *\n","import data\n","from model import SCNN\n","from utils.tensorboard import TensorBoard\n","from utils.transforms import *\n","from utils.lr_scheduler import PolyLR"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Tpwjo8h02zmq","colab_type":"text"},"source":["## Loading a pretrained model if it exists"]}]}