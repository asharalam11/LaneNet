{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing model \n",
    "Here we will test and change the model to understand the features so we can change/modify the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "import os\n",
    "\n",
    "ROOT = '/home/ashar'     # default for the drive\n",
    "CODE = 'LaneNet'       # path to our code on Drive\n",
    "DATASET = 'dataset/trainset'\n",
    "EXPERIMENT = 'LaneNet/config'\n",
    "MODEL_SAVE = 'pretrained'\n",
    "PRETRAINED = 'pretrained'\n",
    "\n",
    "CODE_PATH = join(ROOT, CODE)\n",
    "DATASET_PATH = join(ROOT, DATASET)\n",
    "EXPERIMENT_CONFIG = join(ROOT, EXPERIMENT)\n",
    "MODEL_SAVE = join(ROOT, MODEL_SAVE)\n",
    "PRETRAINED_PATH = join(ROOT, PRETRAINED)\n",
    "\n",
    "# now that we've mounted your Drive, this ensures that\n",
    "# the Python interpreter of the Colab VM can load\n",
    "# python files from within it.\n",
    "import sys\n",
    "sys.path.append('{}'.format(CODE_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing some imports\n",
    "Performing imports necessary for us to be able to import all the features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "#from config import *\n",
    "import data\n",
    "from utils.transforms import *\n",
    "from utils.lr_scheduler import PolyLR\n",
    "\n",
    "# Location of our configuration for training\n",
    "exp_dir = EXPERIMENT_CONFIG + '/cfg.json'\n",
    "exp_name = 'training_accuracy_test'\n",
    "save_dir = MODEL_SAVE + '/' + exp_name\n",
    "with open(exp_dir) as f:\n",
    "  exp_cfg = json.load(f)\n",
    "\n",
    "# Extracting important configurations\n",
    "resize_shape = tuple(exp_cfg['dataset']['resize_shape'])\n",
    "\n",
    "device = torch.device(exp_cfg['device'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data for testing model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data\n",
    "# Predefined mean and std- deviation\n",
    "mean=(0.485, 0.456, 0.406)\n",
    "std=(0.229, 0.224, 0.225)\n",
    "\n",
    "transform_train = Compose(Resize(resize_shape), Rotation(2), ToTensor(),\n",
    "                          Normalize(mean=mean, std=std))\n",
    "\n",
    "import data\n",
    "\n",
    "dataset_name = exp_cfg['dataset']['dataset_name']\n",
    "Dataset_Type = getattr(data, dataset_name)\n",
    "\n",
    "# Training Data\n",
    "train_dataset = Dataset_Type(DATASET_PATH, \"train\", transform_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=exp_cfg['dataset']['batch_size'], shuffle=True, collate_fn=train_dataset.collate, num_workers=8)\n",
    "\n",
    "# Validation Data\n",
    "transform_val_img = Resize(resize_shape)\n",
    "transform_val_x = Compose(ToTensor(), Normalize(mean=mean, std=std))\n",
    "transform_val = Compose(transform_val_img, transform_val_x)\n",
    "val_dataset = Dataset_Type(DATASET_PATH, \"val\", transform_val)\n",
    "#val_loader = DataLoader(val_dataset, batch_size=8, collate_fn=val_dataset.collate, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=20, collate_fn=val_dataset.collate, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determining accuracy and initializing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "##################################################################\n",
    "########\n",
    "#########\n",
    "##################################################################\n",
    "\n",
    "# Extra json files containing dictionary infos\n",
    "train_accuracy_path = os.path.join(DATASET_PATH, \"train_accuracy.json\")\n",
    "val_accuracy_path = os.path.join(DATASET_PATH, \"val_accuracy.json\")\n",
    "test_accuracy_path = os.path.join(DATASET_PATH, \"test_accuracy.json\")\n",
    "\n",
    "with open(train_accuracy_path) as f:\n",
    "  train_accuracy_dict = json.load(f)\n",
    "\n",
    "with open(val_accuracy_path) as f:\n",
    "  val_accuracy_dict = json.load(f)  \n",
    "\n",
    "with open(test_accuracy_path) as f:\n",
    "  test_accuracy_dict = json.load(f)  \n",
    "\n",
    "from utils.prob2lines import getLane\n",
    "from utils.lane_evaluation.tusimple.lane import LaneEval\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# This generates the lane dictionary we need\n",
    "def generate_lanes(seg_label, exist_label, num_pts):\n",
    "  # For prediction\n",
    "  seg = seg_label\n",
    "  exist = [1 if exist_label[i] > 0.5 else 0 for i in range(4)]\n",
    "  lane_coords = getLane.prob2lines_tusimple(seg, exist, resize_shape=(720, 1280), y_px_gap=10, pts = num_pts)\n",
    "  for i in range(len(lane_coords)):\n",
    "      lane_coords[i] = sorted(lane_coords[i], key=lambda pair: pair[1])\n",
    "  lanes = []  # Empty list representing lanes\n",
    "  h_samples = [] # Empty list representing h_samples\n",
    "  # Now let's make a dictionary\n",
    "  for l in lane_coords:\n",
    "      if len(l) == 0:\n",
    "          continue\n",
    "      lanes.append([])\n",
    "      for (x, y) in l:\n",
    "          lanes[-1].append(int(x))\n",
    "  #for (x, y) in lane_coords[0]:\n",
    "      #h_samples.append(y)\n",
    "  return lanes\n",
    "\n",
    "\n",
    "def train_accuracy(gt_lanes, y_samples, seg_pred, exist_pred):\n",
    "  # Workaround \n",
    "  # First we will make the lanes for each of the labels\n",
    "  pred_lanes = generate_lanes(seg_pred, exist_pred, len(y_samples))\n",
    "  \n",
    "  accuracy, positives, negatives = LaneEval.bench(pred_lanes, gt_lanes, y_samples, 0)\n",
    "  # Lets call the function eval\n",
    "  return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train step for testing our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inserting the whole model here for prototyping\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "\n",
    "\n",
    "class SCNN(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            input_size,\n",
    "            ms_ks=9,\n",
    "            pretrained=True\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Argument\n",
    "            ms_ks: kernel size in message passing conv\n",
    "        \"\"\"\n",
    "        super(SCNN, self).__init__()\n",
    "        print(\"no\")\n",
    "        self.pretrained = pretrained\n",
    "        self.net_init(input_size, ms_ks)\n",
    "        if not pretrained:\n",
    "            self.weight_init()\n",
    "\n",
    "        self.scale_background = 0.4\n",
    "        self.scale_seg = 1.0\n",
    "        self.scale_exist = 0.1\n",
    "\n",
    "        self.ce_loss = nn.CrossEntropyLoss(weight=torch.tensor([self.scale_background, 1, 1, 1, 1]))\n",
    "        self.bce_loss = nn.BCELoss()\n",
    "\n",
    "    def forward(self, img, seg_gt=None, exist_gt=None):\n",
    "        x = self.backbone(img)\n",
    "        print(x.shape)\n",
    "        x = self.layer1(x)\n",
    "        x = self.message_passing_forward(x)\n",
    "        x = self.layer2(x)\n",
    "\n",
    "        seg_pred = F.interpolate(x, scale_factor=8, mode='bilinear', align_corners=True)\n",
    "        x = self.layer3(x)\n",
    "        print(x.shape)\n",
    "        x = x.view(-1, self.fc_input_feature)\n",
    "        print(x.shape)\n",
    "        exist_pred = self.fc(x)\n",
    "\n",
    "        if seg_gt is not None and exist_gt is not None:\n",
    "            loss_seg = self.ce_loss(seg_pred, seg_gt)\n",
    "            loss_exist = self.bce_loss(exist_pred, exist_gt)\n",
    "            loss = loss_seg * self.scale_seg + loss_exist * self.scale_exist\n",
    "        else:\n",
    "            loss_seg = torch.tensor(0, dtype=img.dtype, device=img.device)\n",
    "            loss_exist = torch.tensor(0, dtype=img.dtype, device=img.device)\n",
    "            loss = torch.tensor(0, dtype=img.dtype, device=img.device)\n",
    "\n",
    "        return seg_pred, exist_pred, loss_seg, loss_exist, loss\n",
    "\n",
    "    def message_passing_forward(self, x):\n",
    "        Vertical = [True, True, False, False]\n",
    "        Reverse = [False, True, False, True]\n",
    "        for ms_conv, v, r in zip(self.message_passing, Vertical, Reverse):\n",
    "            x = self.message_passing_once(x, ms_conv, v, r)\n",
    "        return x\n",
    "\n",
    "    def message_passing_once(self, x, conv, vertical=True, reverse=False):\n",
    "        \"\"\"\n",
    "        Argument:\n",
    "        ----------\n",
    "        x: input tensor\n",
    "        vertical: vertical message passing or horizontal\n",
    "        reverse: False for up-down or left-right, True for down-up or right-left\n",
    "        \"\"\"\n",
    "        nB, C, H, W = x.shape\n",
    "        if vertical:\n",
    "            slices = [x[:, :, i:(i + 1), :] for i in range(H)]\n",
    "            dim = 2\n",
    "        else:\n",
    "            slices = [x[:, :, :, i:(i + 1)] for i in range(W)]\n",
    "            dim = 3\n",
    "        if reverse:\n",
    "            slices = slices[::-1]\n",
    "\n",
    "        out = [slices[0]]\n",
    "        for i in range(1, len(slices)):\n",
    "            out.append(slices[i] + F.relu(conv(out[i - 1])))\n",
    "        if reverse:\n",
    "            out = out[::-1]\n",
    "        return torch.cat(out, dim=dim)\n",
    "\n",
    "    def net_init(self, input_size, ms_ks):\n",
    "        input_w, input_h = input_size\n",
    "        #self.fc_input_feature = 5 * int(input_w/16) * int(input_h/16)\n",
    "        self.fc_input_feature = 5 * int(input_w/16) * int(input_h/16)\n",
    "        \"\"\"\n",
    "        self.backbone = models.vgg16_bn(pretrained=self.pretrained).features\n",
    "        print(self.backbone)\n",
    "\n",
    "        # ----------------- process backbone -----------------\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # PyTorch v0.4.0\n",
    "        #summary(self.backbone().to(device), (3, 224, 224))\n",
    "        \n",
    "        \n",
    "        for i in [34, 37, 40]:\n",
    "            conv = self.backbone._modules[str(i)]\n",
    "            dilated_conv = nn.Conv2d(\n",
    "                conv.in_channels, conv.out_channels, conv.kernel_size, stride=conv.stride,\n",
    "                padding=tuple(p * 2 for p in conv.padding), dilation=2, bias=(conv.bias is not None)\n",
    "            )\n",
    "            dilated_conv.load_state_dict(conv.state_dict())\n",
    "            self.backbone._modules[str(i)] = dilated_conv\n",
    "        self.backbone._modules.pop('33')\n",
    "        self.backbone._modules.pop('43')\n",
    "        \"\"\"\n",
    "        \n",
    "        ################################## RESNET 18 BACKBONE########################################\n",
    "        model = models.resnet18(pretrained=True)\n",
    "        ## Extracting the model layers as elementst of a list\n",
    "        mod = list(model.children())\n",
    "        # Removing all layers after layer 33\n",
    "        #for i in range(33):\n",
    "        mod.pop()\n",
    "        mod.pop()\n",
    "        mod.pop()\n",
    "        mod.pop()\n",
    "        convolutional = nn.Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0), bias=False)\n",
    "        relu = nn.ReLU(inplace = True)\n",
    "        model = torch.nn.Sequential(*mod, convolutional, relu)\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # PyTorch v0.4.0\n",
    "        self.backbone = model.to(device)\n",
    "        ###############################################################################################\n",
    "        \n",
    "        #print(self.backbone)\n",
    "        \n",
    "        # ----------------- SCNN part -----------------\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(512, 1024, 3, padding=4, dilation=4, bias=False),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(1024, 128, 1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU()  # (nB, 128, 36, 100)\n",
    "        )\n",
    "\n",
    "        # ----------------- add message passing -----------------\n",
    "        self.message_passing = nn.ModuleList()\n",
    "        self.message_passing.add_module('up_down', nn.Conv2d(128, 128, (1, ms_ks), padding=(0, ms_ks // 2), bias=False))\n",
    "        self.message_passing.add_module('down_up', nn.Conv2d(128, 128, (1, ms_ks), padding=(0, ms_ks // 2), bias=False))\n",
    "        self.message_passing.add_module('left_right',\n",
    "                                        nn.Conv2d(128, 128, (ms_ks, 1), padding=(ms_ks // 2, 0), bias=False))\n",
    "        self.message_passing.add_module('right_left',\n",
    "                                        nn.Conv2d(128, 128, (ms_ks, 1), padding=(ms_ks // 2, 0), bias=False))\n",
    "        # (nB, 128, 36, 100)\n",
    "\n",
    "        # ----------------- SCNN part -----------------\n",
    "        self.layer2 = nn.Sequential(\n",
    "            #nn.Dropout2d(0.1),\n",
    "            nn.Dropout2d(0.5),\n",
    "            nn.Conv2d(128, 5, 1)  # get (nB, 5, 36, 100)\n",
    "        )\n",
    "\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Softmax(dim=1),  # (nB, 5, 36, 100)\n",
    "            nn.AvgPool2d(2, 2),  # (nB, 5, 18, 50)\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.fc_input_feature, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 4),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def weight_init(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                m.reset_parameters()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data[:] = 1.\n",
    "                m.bias.data.zero_()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no\n",
      "torch.Size([32, 512, 36, 64])\n",
      "torch.Size([32, 5, 18, 32])\n",
      "torch.Size([32, 2880])\n"
     ]
    }
   ],
   "source": [
    "net = SCNN(resize_shape, pretrained=True)\n",
    "net = net.to(device)\n",
    "net = torch.nn.DataParallel(net)\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), **exp_cfg['optim'])\n",
    "lr_scheduler = PolyLR(optimizer, 0.9, **exp_cfg['lr_scheduler'])\n",
    "best_val_loss = 1e6\n",
    "\n",
    "# Release CUDA memory\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "training_accuracy = 0 # Accuracy per epoch\n",
    "net.train()\n",
    "\n",
    "h_sample = str(-1)  # For accuracy\n",
    "for sample in train_loader:\n",
    "    train_loss_batch = 0  # Training loss for each batch\n",
    "    img = sample['img'].to(device)\n",
    "    segLabel = sample['segLabel'].to(device)\n",
    "    exist = sample['exist'].to(device)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    seg_pred, exist_pred, loss_seg, loss_exist, loss = net(img, segLabel, exist)\n",
    "# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> \n",
    "    # Detaching for out of memory errors\n",
    "    seg_pred_to_pass = F.softmax(seg_pred, dim=1)\n",
    "    seg_pred_to_pass = seg_pred_to_pass.detach().cpu().numpy()\n",
    "    seg_pred = seg_pred.detach().cpu().numpy()\n",
    "    exist_pred = exist_pred.detach().cpu().numpy()\n",
    "\n",
    "    # Accuracy part\n",
    "    for b in range(len(seg_pred)):\n",
    "        lane_index = b\n",
    "        accuracy = train_accuracy(train_accuracy_dict[lane_index][str(lane_index)], train_accuracy_dict[lane_index][h_sample], seg_pred_to_pass[b], exist_pred[b])\n",
    "        training_accuracy += accuracy\n",
    "        #print(accuracy)\n",
    "    \n",
    "    if isinstance(net, torch.nn.DataParallel):\n",
    "            loss_seg = loss_seg.sum()\n",
    "            loss_exist = loss_exist.sum()\n",
    "            loss = loss.sum()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    lr_scheduler.step()\n",
    "\n",
    "    train_loss = loss.item()\n",
    "    train_loss_seg = loss_seg.item()\n",
    "    train_loss_exist = loss_exist.item()\n",
    "\n",
    "    lr = optimizer.param_groups[0]['lr']\n",
    "        \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
